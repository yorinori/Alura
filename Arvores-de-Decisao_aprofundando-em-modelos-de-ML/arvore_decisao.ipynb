{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement scikit-learn==0.21.0 (from versions: 0.9, 0.10, 0.11, 0.12, 0.12.1, 0.13, 0.13.1, 0.14, 0.14.1, 0.15.0, 0.15.1, 0.15.2, 0.16.0, 0.16.1, 0.17, 0.17.1, 0.18, 0.18.1, 0.18.2, 0.19.0, 0.19.1, 0.19.2, 0.20.0, 0.20.1, 0.20.2, 0.20.3, 0.20.4, 0.21.1, 0.21.2, 0.21.3, 0.22, 0.22.1, 0.22.2, 0.22.2.post1, 0.23.0, 0.23.1, 0.23.2, 0.24.0, 0.24.1, 0.24.2, 1.0, 1.0.1, 1.0.2, 1.1.0, 1.1.1, 1.1.2, 1.1.3, 1.2.0rc1, 1.2.0, 1.2.1, 1.2.2)\u001b[0m\n",
      "\u001b[31mERROR: No matching distribution found for scikit-learn==0.21.0\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# !pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: scikit-learn\n",
      "Version: 1.2.2\n",
      "Summary: A set of python modules for machine learning and data mining\n",
      "Home-page: http://scikit-learn.org\n",
      "Author: None\n",
      "Author-email: None\n",
      "License: new BSD\n",
      "Location: /home/yorinori/anaconda3/lib/python3.8/site-packages\n",
      "Requires: numpy, threadpoolctl, joblib, scipy\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show scikit-learn"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02.02 Obtendo a base de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dados = pd.read_csv('data/creditcard.csv')\n",
    "dados.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02.03 Analisando a base de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time      0\n",
      "V1        0\n",
      "V2        0\n",
      "V3        0\n",
      "V4        0\n",
      "V5        0\n",
      "V6        0\n",
      "V7        0\n",
      "V8        0\n",
      "V9        0\n",
      "V10       0\n",
      "V11       0\n",
      "V12       0\n",
      "V13       0\n",
      "V14       0\n",
      "V15       0\n",
      "V16       0\n",
      "V17       0\n",
      "V18       0\n",
      "V19       0\n",
      "V20       0\n",
      "V21       0\n",
      "V22       0\n",
      "V23       0\n",
      "V24       0\n",
      "V25       0\n",
      "V26       0\n",
      "V27       0\n",
      "V28       0\n",
      "Amount    0\n",
      "Class     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(dados.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de transações:  284807\n",
      "Número de fraudes:  492 0.17\n",
      "Número de transações normais:  284315 99.83\n"
     ]
    }
   ],
   "source": [
    "n_trasacoes = dados['Class'].count()\n",
    "n_fraudes = dados['Class'].sum()\n",
    "n_normais = n_trasacoes - n_fraudes\n",
    "fraudes_porc = n_fraudes / n_trasacoes\n",
    "normais_porc = n_normais / n_trasacoes\n",
    "\n",
    "print(\"Número de transações: \", n_trasacoes)\n",
    "print(\"Número de fraudes: \", n_fraudes, \"%.2f\" %(fraudes_porc * 100))\n",
    "print(\"Número de transações normais: \", n_normais, \"%.2f\" %(normais_porc * 100))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O resultado mostra que os dados são desbalanceados.  Há uma alta porcentagem de transações normais e uma pequena porcentagem de transações que são fraudes."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02.05 Criando uma Árvore de Decisão com scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dados.drop('Class', axis=1).values\n",
    "y = dados['Class'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "validador = StratifiedShuffleSplit(n_splits=1, test_size=0.1, random_state=0)\n",
    "\n",
    "for treino_id, teste_id in validador.split(X, y):\n",
    "    X_train, X_test = X[treino_id], X[teste_id]\n",
    "    y_train, y_test = y[treino_id], y[teste_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "classificador_arvore_decisao = tree.DecisionTreeClassifier()\n",
    "arvore = classificador_arvore_decisao.fit(X_train, y_train)\n",
    "y_pred = arvore.predict(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02.06 Gerando uma imagem da árvore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "def validador(X, y):\n",
    "    validador = StratifiedShuffleSplit(n_splits=1, test_size=0.1, random_state=0)\n",
    "\n",
    "    for treino_id, teste_id in validador.split(X, y):\n",
    "        X_train, X_test = X[treino_id], X[teste_id]\n",
    "        y_train, y_test = y[treino_id], y[teste_id]\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7 µs, sys: 0 ns, total: 7 µs\n",
      "Wall time: 8.82 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn import tree\n",
    "\n",
    "def executar_classificador(classificador, X_train, X_test, y_train):\n",
    "    arvore = classificador_arvore_decisao.fit(X_train, y_train)\n",
    "    y_pred = arvore.predict(X_test)\n",
    "\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dados.drop('Class', axis=1).values\n",
    "y = dados['Class'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = validador(X, y)\n",
    "\n",
    "classificador_arvore_decisao = tree.DecisionTreeClassifier()\n",
    "y_pred_arvore_decisao = executar_classificador(classificador_arvore_decisao, X_train, X_test, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02.07 Visualizando os nós e atributos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def salvar_arvore(classificador, nome):\n",
    "    plt.figure(figsize=(200, 100))\n",
    "    tree.plot_tree(classificador, filled=True, fontsize=14)\n",
    "    plt.savefig(nome)\n",
    "    plt.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# execução do validador\n",
    "X = dados.drop('Class', axis=1).values\n",
    "y = dados['Class'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = validador(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# execução do classificador DecisionTreeClassifier\n",
    "\n",
    "# classificador_arvore_decisao = tree.DecisionTreeClassifier()\n",
    "# y_pred_arvore_decisao = executar_classificador(classificador_arvore_decisao, X_train, X_test, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criação da figura da árvore de decisão\n",
    "\n",
    "# salvar_arvore(classificador_arvore_decisao, \"arvore_decisao1.png\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03.02 Medindo a Acurácia da Árvore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def validar_arvore(y_test, y_pred):\n",
    "    print(accuracy_score(y_test, y_pred))\n",
    "    print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9990519995786665\n",
      "[[28419    13]\n",
      " [   14    35]]\n"
     ]
    }
   ],
   "source": [
    "# validação da árvore de decisão\n",
    "\n",
    "validar_arvore(y_test, y_pred_arvore_decisao)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03.03 Medindo além da acurácia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "def validar_arvore(y_test, y_pred):\n",
    "  print(accuracy_score(y_test, y_pred))\n",
    "  print(precision_score(y_test, y_pred))\n",
    "  print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9990519995786665\n",
      "0.7291666666666666\n",
      "[[28419    13]\n",
      " [   14    35]]\n"
     ]
    }
   ],
   "source": [
    "# validação da árvore de decisão\n",
    "\n",
    "validar_arvore(y_test, y_pred_arvore_decisao)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "def validar_arvore(y_test, y_pred):\n",
    "  print(accuracy_score(y_test, y_pred))\n",
    "  print(precision_score(y_test, y_pred))\n",
    "  print(recall_score(y_test, y_pred))\n",
    "  print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9990519995786665\n",
      "0.7291666666666666\n",
      "0.7142857142857143\n",
      "[[28419    13]\n",
      " [   14    35]]\n"
     ]
    }
   ],
   "source": [
    "# validação da árvore de decisão\n",
    "\n",
    "validar_arvore(y_test, y_pred_arvore_decisao)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03.04 Analisando as características da árvore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier()\n",
      "21\n"
     ]
    }
   ],
   "source": [
    "print(classificador_arvore_decisao)\n",
    "print(classificador_arvore_decisao.get_depth())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Limitando a profundidade da árvore em 10 níveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.1 s, sys: 0 ns, total: 10.1 s\n",
      "Wall time: 10.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# execução do classificador DecisionTreeClassifier\n",
    "\n",
    "classificador_arvore_decisao = tree.DecisionTreeClassifier(max_depth=10, random_state=0)\n",
    "y_pred_arvore_decisao = executar_classificador(classificador_arvore_decisao, X_train, X_test, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9994733330992591\n",
      "0.9473684210526315\n",
      "0.7346938775510204\n",
      "[[28430     2]\n",
      " [   13    36]]\n"
     ]
    }
   ],
   "source": [
    "# validação da árvore de decisão\n",
    "\n",
    "validar_arvore(y_test, y_pred_arvore_decisao)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Colocando limite mínimo de 10 transações por folha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# execução do classificador DecisionTreeClassifier\n",
    "\n",
    "classificador_arvore_decisao = tree.DecisionTreeClassifier(max_depth=10, random_state=0, min_samples_leaf=10)\n",
    "y_pred_arvore_decisao = executar_classificador(classificador_arvore_decisao, X_train, X_test, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9993679997191109\n",
      "0.8604651162790697\n",
      "0.7551020408163265\n",
      "[[28426     6]\n",
      " [   12    37]]\n"
     ]
    }
   ],
   "source": [
    "# validação da árvore de decisão\n",
    "\n",
    "validar_arvore(y_test, y_pred_arvore_decisao)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 04.02 Aprendendo o que são os modelos ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# execução do classificador DecisionTreeClassifier com depth = 5\n",
    "\n",
    "classificador_arvore_decisao = tree.DecisionTreeClassifier(max_depth=5, random_state=0)\n",
    "y_pred_arvore_decisao = executar_classificador(classificador_arvore_decisao, X_train, X_test, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.999403110845827\n",
      "0.9210526315789473\n",
      "0.7142857142857143\n",
      "[[28429     3]\n",
      " [   14    35]]\n"
     ]
    }
   ],
   "source": [
    "# validação da árvore de decisão\n",
    "\n",
    "validar_arvore(y_test, y_pred_arvore_decisao)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 04.03 Entendendo a técnica Bagging e o Random Forest"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Bagging* é uma técnica de *ensemble learning*, que é muito popular principalmente por causa do algoritmo random forest. O *bagging* significa *bootstrapping aggregating*. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 04.04 Executando o Random Forest com o scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.08 s, sys: 3.99 ms, total: 5.09 s\n",
      "Wall time: 5.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "classificador_random_forest = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "y_pred_random_forest = executar_classificador(classificador_random_forest, X_train, X_test, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'RandomForestClassifier' object has no attribute 'estimators_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-c0522eaabc93>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msalvar_arvore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassificador_random_forest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"random_forest1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'RandomForestClassifier' object has no attribute 'estimators_'"
     ]
    }
   ],
   "source": [
    "salvar_arvore(classificador_random_forest.estimators_[0], \"random_forest1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.999403110845827\n",
      "0.9210526315789473\n",
      "0.7142857142857143\n",
      "[[28429     3]\n",
      " [   14    35]]\n"
     ]
    }
   ],
   "source": [
    "validar_arvore(y_test, y_pred_random_forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.1 s, sys: 15.9 ms, total: 5.12 s\n",
      "Wall time: 5.18 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "classificador_random_forest = RandomForestClassifier(n_estimators=50, random_state=0, max_depth=10)\n",
    "y_pred_random_forest = executar_classificador(classificador_random_forest, X_train, X_test, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.999403110845827\n",
      "0.9210526315789473\n",
      "0.7142857142857143\n",
      "[[28429     3]\n",
      " [   14    35]]\n"
     ]
    }
   ],
   "source": [
    "validar_arvore(y_test, y_pred_random_forest)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 05.02 Entendendo a técnica boosting e o AdaBoost"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A técnica *boosting*, diferentemente da técnica *bagging* que se baseava em gerar modelos independentes, ou seja, árvores independentes umas das outras e a ideia era que elas fossem mais independentes possíveis. Na técnica *boosting* nós geramos árvores que se completam, ou seja, uma depende da outra. No geral, ela forma um modelo sequencial. Dentro da técnica *boosting* temos um algoritmo que é bem famoso, que eu o **AdaBoost**, “ada” vem de adaptativo. Ou seja, toda vez que uma nova árvore é gerada, ela vai tentar corrigir os erros que a árvore anterior fez, então a ideia é que nós vamos gerando um modelo sequencial de forma que um depende do outro e que um corrija os erros do anterior, até chegarmos no final e termos um resultado bom."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 05.03 AdaBoost: calculando a influência da árvore"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Influência da Árvore:\n",
    "\n",
    "$\\alpha = \\frac{1}{2}log\\left(\\frac{1-\\textrm{Erro Total}}{\\textrm{Erro Total}}\\right)$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 05.04 AdaBoost: calculando o peso das instâncias"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fórmula também para recalcular esses pesos\n",
    "\n",
    "$w_i = w_{i-1} * e^{\\pm \\alpha}$\n",
    "\n",
    "$w$ é o peso e $\\alpha$ é a influência da árvore"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 05.05 AdaBoost: Reagrupando a base de dados"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora já recalculamos o peso das instâncias. Como vamos utilizar isso na nossa fórmula? Qual é o próximo passo agora? Então vai ser da seguinte maneira: o que vamos fazer é construir uma nova base de dados a partir desta.\n",
    "\n",
    "**Ver video da aula para explicação**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 05.06 Executando o AdaBoost com o scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.83 s, sys: 0 ns, total: 4.83 s\n",
      "Wall time: 4.83 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "classificador_adaboost = AdaBoostClassifier(random_state=0, n_estimators=100)\n",
    "y_pred_adaboost = executar_classificador(classificador_adaboost, X_train, X_test, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'AdaBoostClassifier' object has no attribute 'estimators_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-cd6d0b1d303b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msalvar_arvore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassificador_adaboost\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"adaboost1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0msalvar_arvore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassificador_adaboost\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"adaboost2\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mvalidar_arvore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_adaboost\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'AdaBoostClassifier' object has no attribute 'estimators_'"
     ]
    }
   ],
   "source": [
    "salvar_arvore(classificador_adaboost.estimators_[0], \"adaboost1\")\n",
    "salvar_arvore(classificador_adaboost.estimators_[1], \"adaboost2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.999403110845827\n",
      "0.9210526315789473\n",
      "0.7142857142857143\n",
      "[[28429     3]\n",
      " [   14    35]]\n"
     ]
    }
   ],
   "source": [
    "validar_arvore(y_test, y_pred_adaboost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.12 s, sys: 3.94 ms, total: 5.12 s\n",
      "Wall time: 5.12 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "classificador_adaboost = AdaBoostClassifier(random_state=0, n_estimators=200)\n",
    "y_pred_adaboost = executar_classificador(classificador_adaboost, X_train, X_test, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.999403110845827\n",
      "0.9210526315789473\n",
      "0.7142857142857143\n",
      "[[28429     3]\n",
      " [   14    35]]\n"
     ]
    }
   ],
   "source": [
    "validar_arvore(y_test, y_pred_adaboost)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pendências"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AttributeError: 'RandomForestClassifier' object has no attribute 'estimators_'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fim do curso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
